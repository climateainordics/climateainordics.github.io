---
title: 2025 Nordic Workshop on AI for Climate Change
shortversion: "The 2025 Nordic Workshop on AI for Climate Change will gather researchers from the Nordics. This one-day, in-person workshop, will take place in Gothenburg, Sweden, May 13th 2025. The workshop will feature a mix of keynotes, oral presentations, and posters around the topics of AI for climate change, including AI for biodiversity and the green transition. The workshop will be a meeting point for a wide range of researchers from (primarily) around the Nordic countries."
people:
- Olof Mogren
image: /images/nordic-workshop-1200x846.png
---

<style>
img {
  width: 12em;
  float: right;
  padding: 1em 0em 1em 1em;
}
</style>


## Schedule

*This schedule is a work in progress. Expect changes.*

| Time | Category | Speaker | Title |
| ---- | --- | ------- | ----- |
| 9:00 | | Coffee/find your seat | | 
| 9:10 | | Olof Mogren | Opening remarks |
| 9:15 | Keynote | [Oisin Mac Aodha](#oisin) | [AI-Powered Biodiversity Monitoring](#oisin) |
| 10:00 | Oral | [Edmond Sacre](#edmond) | [Mapping and conservation of aquatic species - potential advances with deep learning](#edmond) |
| 10:20 | Oral | [Hilda Sandström](#hilda) | [Machine Learning for Mass Spectrometry in Atmospheric Chemistry](#hilda) |
| 10:40 | | Coffee break |  |
| 11:10 | Oral | [Dan Stowell](#dan) | [Bioacoustic AI for nature: how can it tread lightly?](#dan) |
| 11:40 | Oral | [John Martinsson](#john) | [Better Labels, Better AI: Enhancing Bioacoustic Event Detection for Biodiversity Monitoring](#john) |
| 12:00 | | Lunch |  |
| 13:15 | Keynote | [Christian Igel](#christian) | [Deep learning for large-scale ecosystem monitoring](#christian) |
| 14:00 | Oral | [Nico Lang](#nico) | [Learning From Global Earth Observation Data](#nico) |
| 14:20 | Oral | [Stefanos Georganos](#stefanos) | [Unequal Cities in a Changing Climate: AI and Geospatial Approaches to Urban Resilience](#stefanos) |
| 14:40 | | Coffee |  |
| 15:10 | Oral | [Alouette van Hove](#alouette) | [Navigating methane plumes: A journey from drone observations to flux estimates](#alouette) |
| 15:30 | Oral | [Shorouq Zahra](#shorouq) | [The challenges of using LLMs to extract data on extreme climate events](#shorouq) |
| 15:50 | Oral | [David Thulke](#david) | [Assessing and Improving ClimateGPT's Faithfulness in Retrieval Augmented Generation](#david) |
| 16:10 | | [Posters and mingle](#posters) |  |
| 17:45 | | Concluding remarks |  |
| 18:00 | | Dinner | |

<a name="posters"></a>
## 16:10 - 17:45 Poster presentations

| No. | Speaker | Title |
|---- | -------------------------- | --------------------------------------------------------------- |
| 1   | [Sonja Aits](#sonja) | [TBA](#sonja) |
| 2   | [Adrià Amell](#adria) | [RainOverAfrica.AI: nowcasting precipitation from geostationary imagery](#adria) |
| 3   | [Anna Luise Von Blohn](#anna) | [TBA](#anna) |
| 4   | [Benjamin Cretois](#benjamin) | [TBA](#benjamin) |
| 5   | [Ellen Dejonghe](#ellen) | [TBA](#ellen) |
| 6   | [Luisa Delgado-Márquez](#luisa) | [TBA](#luisa) |
| 7   | [Filip Dorm](#filip) | [Large language models possess some ecological knowledge, but how much?](#filip) |
| 8   | [Patrick Eriksson](#patrick) | [Providing space-borne ML-based atmospheric data with case-specific uncertainties](#patrick) |
| 9  | [Ramon Fuentes Franco](#ramon) | [Pan-European high-resolution downscaling using deep learning](#ramon) |
| 10  | [Lucia Gordon](#lucia) | [MMEarth-Bench: Global Environmental Tasks for Multimodal Geospatial Models](#lucia) |
| 11  | [Leon Green](#leon) | [Tracking the population and interactions of Sweden’s most abundant invasive fish using an image recognition algorithm](#leon) |
| 12  | [Céline Heuzé](#celine) | [Drivers of high frequency extreme sea level around Northern Europe – Synergies between recurrent neural networks and Random Forest](#celine) |
| 13  | [Ankit Kariryaa](#ankit) | [TBA](#ankit) |
| 14  | [Murathan Kurfali](#murathan) | [ClimateEval: A Comprehensive Benchmark for Climate Change NLP](#murathan) |
| 15  | [Francesca Larosa](#francesca) | [TBA](#francesca) |
| 16  | [Ashwin Mohanan](#ashwin) | [Dawsonia: Digitizing handwritten observations in weather journals](#ashwin) |
| 17  | [Andrea Nascetti](#andrea) | [PANGEA: A Global And Inclusive Benchmark For Geospatial Foundation Models](#andrea) |
| 18  | [Aleksis Pirinen, Olof Mogren](#aleksis) | [TBA](#aleksis) |
| 19  | [Stefano Puliti](#puliti) | [Leveraging NFI Image Data for Large-Scale Forest Biodiversity Monitoring](#puliti) |
| 20  | [Laura Helene Rasmussen](#laura) | [Quantifying the variability of winter climate in the Arctic](#laura) |
| 21  | [Heather Reese](#heather) | [Subarctic tundra change mapping with Earth Observation and machine learning](#heather) |
| 22  | [Jaime Caballer Revenga](#jaime) | [Self-supervised segmentation of environmental spectroscopic imagery benefits from phenology trajectories](#jaime) |
| 23  | [Alan Said](#alan) | [Accountability and sustainability in AI: reducing the environmental footprint of ai research](#alan) |
| 24  | [Hui Zhang](#hui) | [Towards vertical vegetation structure models](#hui) |
| 25  | [Dan Stowell](#dan) | [Bioacoustic AI for nature: how can it tread lightly?](#dan) |
| 26  | [Anupama Xavier](#anupama) | [Comparative predictability of eastern and western north pacific blocking events](#anupama) |


## Speaker instructions.

For speakers, see presentation instructions [here](speaker-instructions.html).




## Details

<a name="oisin"></a>
**9:15 Keynote: Oisin Mac Aodha,** University of Edinburgh

![](/events/2025-nordic-workshop/macaodha.jpg)

**Title**: AI-Powered Biodiversity Monitoring

**Abstract**: TBA

*Oisin Mac Aodha is a Reader (aka Associate Professor) in Machine Learning in the School of Informatics at the University of Edinburgh (UoE). He was a Turing Fellow from 2021 to 2024, currently an ELLIS Scholar, and a founder of the Turing interest group on biodiversity monitoring and forecasting. Oisin's current research interests are in the areas of computer vision and machine learning, with a specific emphasis on 3D understanding, human-in-the-loop methods, and computational challenges in biodiversity monitoring.*

[Back to top of page](#top)

<a name="edmond"></a>
**10:00 Oral: Edmond Sacre,** Swedish University of Agricultural Sciences

![](/events/2025-nordic-workshop/sacre.jpg)

**Title**: Mapping and conservation of aquatic species - potential advances with deep learning

**Abstract**: In the field of conservation planning, a great deal of effort and research has gone into the spatial modelling (i.e. mapping) of species, habitats, and other ecological processes. These models and data are a crucial component of conservation decision making, such as where to place protected areas and where to focus habitat restoration efforts. However, producing such maps is often challenging where data are limited. This is particularly true in aquatic environments, which are inherently more difficult to sample and remotely observe. To date, species distribution models have typically employed traditional statistical or machine learning techniques. There exists, therefore, great potential to improve these methods using more advance deep learning methods, which could lead to great improvements in map accuracy and, therefore, better conservation decisions. These powerful methods could also be used not only to produce maps of species distributions today, but also to predict where species may occur in the future under different climate scenarios, and where they might have occurred in the past.

*E. Sacre is a researcher at the Swedish University of Agricultural Sciences (SLU) within the Department of Aquatic Resources (SLU Aqua). He obtained his PhD in 2019 at James Cook University, Australia, within the Australian Research Council Centre of Excellence for Coral Studies. At SLU Aqua, Edmond works within the Unit for Conservation and Marine Spatial Planning where he has been employed since 2019. He is involved in a variety of national and international projects focused on species distribution modeling, spatial conservation planning, cumulative impact assessment, and connectivity modeling. These projects include Protect Baltic (EU-Horizon), Western Indian Ocean Symphony (Swedish Agency for Marine and Water Management), and other national mapping projects.*

[Back to top of page](#top)

<a name="hilda"></a>
**10:00 Oral: Hilda Sandström,** Aalto University

![](/events/2025-nordic-workshop/sandstrom.jpg)

**Title**: Machine Learning for Mass Spectrometry in Atmospheric Chemistry

**Abstract**: Mass spectrometry is a key technique for analyzing the chemical composition of the atmosphere, helping to identify pollutants, track chemical reactions, and understand the formation of airborne particles. However, interpreting mass spectrometry data is challenging due to the vast number of molecules involved, their low concentrations, and their variability. Machine learning is increasingly being used to enhance both experimental design and the identification of unknown compounds, enabling new insights from mass spectrometry data.

This talk will explore two key ways in which machine learning can be utilized for mass spectrometry in atmospheric chemistry. One application focuses on optimizing experimental techniques by predicting how different chemicals behave during analysis, improving the detection of substances such as pesticides. Another application involves identifying unknown molecules by recognizing patterns in their chemical properties and reactivities, offering a clearer understanding of atmospheric processes leading to the formation of atmospheric particles.

*Hilda Sandström is a computational chemist specializing in atmospheric chemistry and astrochemistry. She obtained her graduate degree from Chalmers University of Technology in computational chemistry applied to the (astro-) chemistry of hydrogen cyanide and its polymers. Since two years, she is a postdoctoral researcher at Aalto University and the Virtual laboratory for molecular level atmospheric transformations (VILMA) center of excellence in Espoo, Finland.*

[Back to top of page](#top)

<a name="dan"></a>
**11:10 Oral: Dan Stowell,** Tilburg University

![](/events/2025-nordic-workshop/stowell.jpg)

**Title**: Bioacoustic AI for nature: how can it tread lightly?

**Abstract**: The biodiversity crisis is deeply entwined with the climate crisis. Worse, we only know part of the picture of biodiversity: less than one-quarter of the world's species have even been described, let alone monitored. The monitoring task is so large that it necessitates automation: AI can help. I will introduce some of the latest work in bioacoustic AI, for sensing the sounds of wildlife. But this leads to a follow-on question: is it even possible to roll out AI sensing at massive scale, without imposing a heavy burden of carbon emissions and e-waste? I will discuss these risks, and then I will compare the environmental costs and benefits of the tools in our bioacoustic toolbox.

*Dan Stowell is an Associate Professor of AI & Biodiversity working in the Netherlands (Tilburg University, Naturalis Biodiversity Centre, JADS). His research is about machine listening and computational bioacoustics - which means using computation (especially machine learning) to understand animal sounds and other sound signals.*

*- I develop automatic processes to analyse large amounts of sound
recordings - for example detecting the bird sounds in there and how they vary, how they relate to each other, how the birds' behaviour relates to the sounds they make. The research work is focussed on the machine learning and signal processing methods that can help with these questions. I also work with others to apply these methods to biodiversity monitoring.*

*Dan also works with OpenClimateFix and OpenStreetMap on addressing climate change through solar panel mapping.*

[Back to top of page](#top)

<a name="john"></a>
**11:40 Oral: John Martinsson,** RISE Research Institutes of Sweden

![](/events/2025-nordic-workshop/martinsson.webp)

**Title**: Better Labels, Better AI: Enhancing Bioacoustic Event Detection for Biodiversity Monitoring

**Abstract**: Robust bioacoustic monitoring is essential for biodiversity research, providing valuable insights into species presence, behavior, and ecosystem health. AI-driven approaches have the potential to scale these efforts, but their effectiveness critically depends on the quality of labeled data. However, manual annotation of animal vocalizations is often time-consuming, costly, and prone to inconsistencies. In this talk, I will present novel active labeling methods for audio that focus on streamlining annotation workflows and enhancing label quality to strengthen bioacoustic event detection performance. In addition, I will share early insights from an ongoing bioacoustics collaboration, where we are analyzing audio recordings from a Guillemot colony at Stora Karlsö. This case study highlights both the challenges and opportunities in improving AI-based bioacoustics monitoring, ultimately contributing to more reliable and scalable conservation efforts in Nordic environments.

*John Martinsson is a researcher specializing in machine listening-using machine learning to analyze audio data-and its application to bioacoustics and biodiversity monitoring. A key focus of his research is on streamlining the often labor-intensive process of labeling bioacoustic data, and on creating robust models that perform effectively even with limited labeled data. More information on his website: [johnmartinsson.org](https://johnmartinsson.org/).*

[Back to top of page](#top)

<a name="christian"></a>
**13:15 Keynote: Christian Igel,** University of Copenhagen

![](/events/2025-nordic-workshop/igel.jpg)

**Title**: Deep learning for large-scale ecosystem monitoring

**Abstract**: Tree-based ecosystems play an important role for carbon sequestration and biodiversity as well as for timber and food production. We need a better characterization of woody resources at a global scale to understand how these ecosystems are affected by climate change and human management. Recent advances in remote sensing and machine learning (ML) based computer vision make this possible. Deep learning applied to high-resolution satellite imagery allows, for example, for large-scale mapping of individual trees. The biomass of each tree, and thereby its carbon content, can then be estimated from the crown size using allometric equations learned from data. The functional relation is assumed to be non-decreasing, and incorporating this constraint into ML-based modelling increase the scientific plausibility and acts as a strong regularizer. We highlight an application of tree carbon stock quantification in Rwanda, where it helps developing pathways to reach the country’s sustainable development goals. The talk closes with a presentation of recently released open source image data sets for training ML models for different environmental monitoring tasks.

*Christian Igel is a professor at DIKU, the Department of Computer Science at the University of Copenhagen. He is the director of the SCIENCE AI Centre. Furthermore, he is a co-lead of the Pioneer Centre for Artificial Intelligence, Denmark and a Fellow of ELLIS, European Lab for Learning and Intelligent Systems. Christian's reserach interests include support vector machines and other kernel-based methods,evolution strategies for single- and multi-objective optimization and reinforcement learning, PAC-Bayesian analysis of ensemble methods, deep neural networks and stochastic neural networks, and applications of machine learning that help achieve the sustainable development goals.*

[Back to top of page](#top)

<a name="nico"></a>
**14:00 Oral: Nico Lang,** University of Copenhagen and Pioneer Centre for AI

![](/events/2025-nordic-workshop/lang.jpg)

**Title**: Learning From Global Earth Observation Data

**Abstract**: The volume of unlabeled Earth observation (EO) data is huge. To interpret this vast amount of data, efficient modelling approaches are needed that can generalize to large geographic areas and are robust to inherent noise. Data-driven approaches promise great potential for interpreting and combining data from different space missions. In this talk, I will present our work on global canopy height mapping with optical satellite images and sparse spaceborne lidar data and discuss a recent project called MMEarth that explored multi-modal pretext tasks for learning representations that are suitable for a range of downstream tasks with limited training data. 

*Nico is an Assistant Professor at the University of Copenhagen associated with the Global Wetland Centre and the Pioneer Centre for AI, where he is co-advised by Serge Belongie and Christian Igel. He has received a PhD from ETH Zurich, under the supervision of Konrad Schindler and Jan Dirk Wegner. His research interests are at the intersection of computer vision and remote sensing, currently focusing on open-world recognition, fine-grained categorization, and representation learning with multi-modal data. More information can be found on his website: https://langnico.github.io/*

[Back to top of page](#top)

<a name="stefanos"></a>
**14:20 Oral: Stefanos Georganos,** Karlstad University: Unequal Cities in a Changing Climate: AI and Geospatial Approaches to Urban Resilience

![](/events/2025-nordic-workshop/georganos.jpg)

**Title**: Unequal Cities in a Changing Climate: AI and Geospatial Approaches to Urban Resilience

**Abstract**: Cities in the Global South face mounting challenges from rapid urbanization and climate change, with millions residing in deprived areas or so-called ‘slums.’ This presentation explores how AI-driven geospatial techniques—leveraging Earth Observation (EO) and GIS data—can enhance the mapping and understanding of urban vulnerability and deprivation. By integrating EO data with automated approaches, these methods reveal spatial inequalities that are often exacerbated by climate change and overlooked by traditional surveys and censuses. The insights gained support equitable resource allocation and inform policy interventions aimed at fostering more resilient and sustainable urban futures for some of the most vulnerable communities.

*Stefanos Georganos is an Associate Professor in Geomatics at Karlstad University. He does research in quantitative human geography, remote sensing, spatial epidemiology, demography and machine learning. He is particularly interested in the use of geo-information for helping address the UN Sustainable Development Goals, with a geographical interest in sub-Saharan African cities. His latest research unravels the potential of machine and deep learnning and Earth Observation to detect, measure and characterize socio-economic inequalities in deprived urban areas in support of the most vulnerable populations.*

[Back to top of page](#top)

<a name="alouette"></a>
**15:10 Oral: Alouette van Hove,** University of Oslo

![](/events/2025-nordic-workshop/van-hove.jpg)

**Title**: Navigating methane plumes: A journey from drone observations to flux estimates

**Abstract**: Accurate regional mapping of methane emissions remains a challenge in climate science, contributing to uncertainties in national emission inventories and climate change projections. To address this issue, we have developed a novel observing system that assimilates drone observations into an atmospheric dispersion model to estimate methane emission rates effectively. In this presentation, we will discuss the application of our Bayesian framework to evaluate methane emissions from various livestock herds in Kenya. Additionally, our ongoing system development focuses on optimizing drone sampling paths to collect the most informative data, even in unfamiliar environments. Through synthetic experiments, we investigate how reinforcement learning can improve sampling strategies, enabling drones to efficiently acquire data and infer more accurate methane emission rate estimates.

*Alouette van Hove is a PhD candidate at the University of Oslo. Her research interests includes the development of a novel framework to estimate land surface fluxes at a regional scale. The framework makes use of sensor measurements from drones, data assimilation, atmospheric fluid dynamics modeling, and reinforcement learning techniques. The goal is to deliver high-resolution surface maps of greenhouse gas fluxes in northern landscapes for validation of climate models.*

[Back to top of page](#top)

<a name="shorouq"></a>
**15:30 Oral: Shorouq Zahra,** RISE Research Institutes of Sweden

![](/events/2025-nordic-workshop/zahra.jpg)

**Title**: The challenges of using LLMs to extract data on extreme climate events

**Abstract**: Large volumes of data on extreme climate impacts are buried in copious amounts of text, such as in Wikipedia articles. Such data is essential for climate change research as well as for building downstream applications like climate impact forecasting or early warning systems. Even though a number of manually-created extreme climate event databases exist, they may (a) be skewed towards under-reporting impacts in certain regions or languages; (b) require extensive manual labor to produce, update and quality-check; and (c) possibly limit the potential hazard impact analyses due to lacking uniformity or using different categorization schemes. This presentation will walk you through the successes and challenges faced when building and testing an LLM-based extraction pipeline for climate-related texts that attempts to address some of these shortcomings. The final product, Wikimpacts v1.0, presents a large-scale database of extreme climate impacts (caused by, for example, floods, droughts, or tornadoes) in terms of both human cost and material loss.

*Shorouq Zahra a research engineer and developer at RISE Research Institutes of Sweden, with a focus on NLP, conversational AI, and MLOps. She has been engaged in the work "Using LLMs to Build a Database of Climate Extreme Impacts", presented at ClimateNLP 2024, proposing a method for building large-scale databases of climate extreme impacts from online textual sources, using LLMs for information extraction in combination with more traditional NLP techniques to improve accuracy and consistency.*

[Back to top of page](#top)

<a name="david"></a>
**15:50 Oral: David Thulke,** RWTH Aachen University

![](/events/2025-nordic-workshop/thulke.jpg)

**Title**: Assessing and Improving ClimateGPT's Faithfulness in Retrieval Augmented Generation

**Abstract**: Large language models utilising retrieval augmented generation have the potential to unlock valuable knowledge for researchers, policymakers, and the public by making long and technical climate-related documents more accessible. While this approach can help alleviate factual hallucinations by relying on retrieved passages as additional context, its effectiveness depends on whether the model’s output remains faithful to these passages. To address this, we explore approaches to automatically assess the faithfulness of different models in this setting. We then focus on ClimateGPT, a large language model specialised in climate science, to examine which factors in instruction fine-tuning impact the model's faithfulness.

*David Thulke is a PhD student within the Human Language Technology Group at the Chair of Computer Science 6 of the RWTH Aachen University supervised by Prof. Dr.-Ing. Hermann Ney. In addition to numerous other works on language models and retrieval augmented generation, he is the first author of ClimateGPT, a model family of domain-specific large language models for information retrieval and generation. He also works as a language processing scientist at AppTek.*

[Back to top of page](#top)


## Poster presentation details

<a name="sonja"></a>
**1. Sonja Aits**<br />
**Title**: TBA<br />
**Abstract**: TBA

[Back to top of page](#top)

<a name="adria"></a>
**2. Adrià Amell**<br />
**Title**: RainOverAfrica.AI: nowcasting precipitation from geostationary imagery<br />
**Abstract**: Geostationary satellites offer an unrivalled spatiotemporal coverage, but their measurements have often been considered only complementary for the complex problem of estimating precipitation from space. We present Rain over Africa (RoA), a method based on a neural network and geostationary imagery that can provide not only continuous precipitation estimates over the entire African continent but also case-specific uncertainties, facilitating the detection of extreme events. Anyone can produce RoA estimates with a latency of about one minute after the dissemination of satellite data, enabling resilience planning through near real-time monitoring. This nowcasting aspect of RoA is not at the expense of accuracy, since it results superior to established higher latency products.	

[Back to top of page](#top)

<a name="anna"></a>
**3. Anna Luise Von Blohn**<br />
**Title**: <br />
**Abstract**: TBA

[Back to top of page](#top)

<a name="benjamin"></a>
**4. Benjamin Cretois**<br />
**Title**: <br />
**Abstract**: TBA

[Back to top of page](#top)

<a name="ellen"></a>
**5. Ellen Dejonghe**	<br />
**Title**: TBA<br />
**Abstract**: TBA


[Back to top of page](#top)

<a name="luisa"></a>
**6. Luisa Delgado-Márquez**	<br />
**Title**: <br />
**Abstract**: TBA


[Back to top of page](#top)

<a name="filip"></a>
**7. Filip Dorm**<br />
**Title**: Large language models possess some ecological knowledge, but how much?<br />
**Abstract**: Large Language Models (LLMs) have garnered attention for their potential at question answering across multiple different domains. However, despite the promise demonstrated, there has only been limited exploration of their effectiveness in the context of ecological knowledge. We investigate the ecological knowledge and potential reasoning abilities of two LLMs, Gemini 1.5 Pro and GPT-4o, across a suite of ecologically focused tasks. Our tasks quantitatively assess a models’ ability to predict species presence at locations, generate range maps, list critically endangered species, classify threats, and estimate species traits. We compare model performance against expert-derived data to quantify their accuracy and reliability using a new benchmark dataset we introduce. We show that while the LLMs tested outperform naive baselines, they still exhibit significant limitations, particularly in generating spatially accurate range maps and classifying threats. Our findings underscore both the potential and challenges of using LLMs in ecological applications, highlighting the need for further refinement, including domain-specific fine-tuning, to better approximate ecological reasoning. Our new benchmark dataset will enable researchers to make progress on this task by providing a repeatable way to evaluate future models.	

[Back to top of page](#top)

<a name="patrick"></a>
**8. Patrick Eriksson** <br />
**Title**: Providing space-borne ML-based atmospheric data with case-specific uncertainties<br />
**Abstract**: Only satellite measurements enable regional and global observations of quantities such as rainfall or cloudiness. However, there is often not a unique solution to the problem of translating the quantities measured by space-borne instruments into geophysical values. Traditional approaches to the problem fail to provide statistically sound estimates for many properties or are too expensive. At the Division of Geoscience and Remote Sensing of Chalmers University of Technology, we have been working with the flexibility of quantile regression neural networks to provide affordable but accurate statistical descriptions of space-borne estimates of precipitation and atmospheric ice densities, both a cornerstone of climate studies.	

[Back to top of page](#top)

<a name="ramon"></a>
**9. Ramon Fuentes Franco**<br />
**Title**: Pan-European high-resolution downscaling using deep learning<br />
**Abstract**: This study assesses the performance of a deep convolutional neural network in predicting near-surface air temperature (T2m) and total precipitation (P) over Europe, comparing its results with the Copernicus European Regional Reanalysis (CERRA) and the dynamical regional model HCLIM simulations. The ML-model accurately captures broad seasonal temperature and precipitation patterns, with minor biases in summer and more pronounced warm biases in winter. While the model effectively reproduces the probability density functions (PDFs) of daily temperature and precipitation, it underestimates extreme cold events and in some regions also the high precipitation extremes. Climate indices, including cold extremes (TM2PCTL), warm extremes (TM98PCTL), consecutive dry days (CDD), and consecutive wet days (CWD), highlight that the ML-model aligns closely with CERRA, though it slightly underestimates CDD and overestimates CWD, particularly in mountainous and Mediterranean regions. Analysis of spatio-temporal variability demonstrates high correlations with CERRA for temperature, exceeding 0.99 for spatial correlations and 0.95 for temporal correlations, while correlations for precipitation are lower, with underestimated temporal variability. The ML-model generally outperforms HCLIM, particularly in aligning with observed data, although challenges remain in capturing extremes and reducing biases in certain regions. These results further highlight the potential of the ML-model for regional climate downscaling and impact studies, while emphasizing the need for further refinement to enhance its representation of extreme events and improve spatial accuracy.	

[Back to top of page](#top)

<a name="lucia"></a>
**10. Lucia Gordon**<br />
**Title**: MMEarth-Bench: Global Environmental Tasks for Multimodal Geospatial Models<br />
**Abstract**: Pretraining deep neural networks in a self-supervised manner on large datasets can produce models that generalize to a variety of downstream tasks. This is especially beneficial for environmental monitoring tasks where reference data is often limited, preventing the application of supervised learning. Models that can interpret multimodal data to resolve ambiguities of single-modality inputs may have improved prediction capabilities on remote sensing tasks.Our work fills an important gap in existing benchmark datasets for geospatial models. First, our benchmark focuses on the natural world, whereas many existing datasets focus on the built-up world. Second, existing datasets tend to be local or cover relatively small geographic regions in the global North. However, evaluating and distinguishing performance among pretrained models that aim to contribute to planet-scale environmental monitoring requires downstream tasks that are distributed around the globe. Third, existing datasets include only a few modalities as input (e.g., RGB, Sentinel-1 (S1) SAR, and Sentinel-2 (S2) optical images), even though many additional data modalities are relevant to environmental prediction tasks.We present MMEarth-Bench, a collection of datasets for various global-scale environmental monitoring tasks. MMEarth-Bench consists of five downstream tasks of high relevance to climate change mitigation and biodiversity conservation: aboveground biomass, species occurrence, soil nitrogen, soil organic carbon, and soil pH. Each downstream task dataset is aligned with the twelve modalities comprising the MMEarth dataset, designed for global multimodal pretraining, including S2 optical images, S1 SAR, elevation, canopy height, landcover, climate variables, location, and time. We use MMEarth-Bench to evaluate pretrained models, often called “foundation models,” that make use of multiple modalities during inference, as opposed to utilizing just a single modality such as optical images. We demonstrate the importance of making use of many modalities at test time in environmental monitoring tasks and also evaluate the geographic generalization capabilities of existing models.


[Back to top of page](#top)

<a name="leon"></a>
**11. Leon Green**<br />
**Title**: Tracking the population and interactions of Sweden’s most abundant invasive fish using an image recognition algorithm.<br />
**Abstract**: Introductions of invasive species in the marine environment is increasing along with global shipping intensity. Climate change exarcebates this, while also stressing native communitites of animals making them more susceptible. To understand the impacts on biodiversity from these cumulative stressors, society needs to harness cost-effective monitoring solutions. A promising method that can yield high accuracy data is computer vision paired with deep-learning to construct object-detection models. This approach is gaining momentum in ecology, and several identification technologies are available to utilize for this approach. For animal detection and identification, the most used algorithms are from the deep neural-network (DNN) based YOLO series. In short, the algorithm is fed training images (input), and depending on how well it classifies an object (the output), the connection through this network is reinforced or weakened to improve the likelihood of input and output matching the next time. Here, we present an object-detection model created to automatically identify and track Swedens first invasive marine fish (the round goby) from underwater video. Importantly, it is also able to distinguish the species from the very similar native black goby and other commonly encountered animals. This model has been created using the with support from an online citizen science community, where people classify fish from videos and photos. These classification were then used to train the object-detection model using deep-learning neural networks in PyTorch using the ultralythics YOLOv8 package. Through this computer vision AI, we have created an accurate method to monitor small, well camouflaged invasive fish in the wild to determine impacts from biological invasions.	

[Back to top of page](#top)

<a name="celine"></a>
**12. Céline Heuzé** <br/>
**Title**: Drivers of high frequency extreme sea level around Northern Europe – Synergies between recurrent neural networks and Random Forest<br />
**Abstract**: Northern Europe is particularly vulnerable to extreme sea level events as most of its large population, financial and logistics centres are located by the coastline. Policy makers need information to plan for near- and longer-term events. There is a consensus that for Europe, in response to climate change, changes to extreme sea level will be caused by mean sea level rise rather than changes in its drivers, meaning that determining current drivers will aid such planning. Here we determine from explainable AI the meteorological and hydrological drivers of high frequency extreme sea level at nine locations on the wider North Sea – Baltic coast using Long Short Term Memory (LSTM, a type of deep recurrent neural network) and the simpler Random Forest regression on hourly tide gauge data. LSTM is optimised for targeting the excess values, or periods of prolonged high sea level; Random Forest, the block maxima, or most extreme peaks in sea level. Through permutation feature of the LSTM, we show that the most important driver of the periods of high sea level over the region is the westerly winds, whereas the Random Forest reveals that the driver of the most extreme peaks depends on the geometry of the local coastline. LSTM is most accurate overall, although predicting the highest values without overfitting the model remains challenging. Despite being less accurate, Random Forest agrees well with the LSTM findings, making it suitable for predictions of extreme sea level events at locations with short and/or patchy tide gauge observations.

More information at https://egusphere.copernicus.org/preprints/2025/egusphere-2025-700/

[Back to top of page](#top)

<a name="ankit"></a>
**13. Ankit Kariryaa**	<br />
**Title**: TBA<br />
**Abstract**: TBA


[Back to top of page](#top)

<a name="murathan"></a>
**14. Murathan Kurfali**<br />
**Title**: ClimateEval: A Comprehensive Benchmark for Climate Change NLP<br />
**Abstract**: We introduce ClimateEval, a comprehensive benchmark designed to evaluate natural language processing models across a broad range of tasks related to climate change. ClimateEval aggregates existing datasets along with a newly developed news classification dataset, created specifically for this release. This results in a benchmark of 25 tasks based on 13 datasets, covering key aspects of climate discourse, including text classification, question answering, and information extraction. Our benchmark provides a standardized evaluation suite for systematically assessing the performance of large language models (LLMs) on these tasks. Additionally, we conduct an extensive evaluation of open-source LLMs (ranging from 2B to 70B parameters) in both zero-shot and few-shot settings, analyzing their strengths and limitations in the domain of climate change.

[Back to top of page](#top)

<a name="francesca"></a>
**15. Francesca Larosa**<br />
**Title**: TBA<br />
**Abstract**: TBA


[Back to top of page](#top)

<a name="ashwin"></a>
**16. Ashwin Mohanan**<br />
**Title**: Dawsonia: Digitizing handwritten observations in weather journals<br />
**Abstract**: Nearly all meteorological agencies in the world, including SMHI, possesses troves of archived observations spanning decades in paper format. Dawsonia is a proof-of-concept application which combines accurate computer vision algorithms and machine learning models to handle different forms of tabular data, convert handwritten text and produce machine-readable files. This would aid and accelerate the digitization work from the paper archives into data, which is done manually as of now. As a result of the project, SMHI aims at digitizing numerous historical weather observations that will help a better understanding of the climate, especially of the occurrence of extreme weather events.

The method implemented in Dawsonia is presented along with the development process. We also describe how the machine learning models were trained on LUMI, an EuroHPC supercomputer with technical support from ENCCS.

Repository: https://git.smhi.se/ai-for-obs/dawsonia
Documentation: https://dawsonia.readthedocs.io/
Demo: https://hf.co/spaces/ai-for-obs/dawsonia-demo"	

[Back to top of page](#top)

<a name="andrea"></a>
**17. Andrea Nascetti**<br />
**Title**: PANGEA: A Global And Inclusive Benchmark For Geospatial Foundation Models<br />
**Abstract**: Geospatial Foundation Models (GFMs) have emerged as a promising technology for extracting representations from Earth observation (EO) data, with applications spanning urban planning, agriculture, disaster response, and more. These models, trained on large-scale EO datasets, aim to extract fundamental geospatial features that can be applied to a range of downstream tasks. However, the rapid development of GFMs has outpaced the establishment of a robust and standardized evaluation methodology, hindering the ability to effectively assess their real-world applicability. Existing works often evaluate on suboptimal downstream datasets and tasks, that are often too easy (e.g., EuroSAT, which reports >99% accuracy) or too narrow, limiting the usefulness of the evaluations to assess real-world applicability of GFMs.These benchmarks overlook critical factors, such as the diversity of sensor types, spatial resolutions, temporal dynamics, and geographical representation, limiting their capacity to evaluate the true potential of GFMs. For instance, the PhilEO Bench [1], though a valuable contribution, evaluates models only through the lens of Sentinel-2 data, limiting the breadth of the conclusions that can be drawn from this benchmark. In comparison, GEO-Bench [2] and SustainBench [3], include data from multiple sensors; however, they cover only land observations, ignore marine environments, consider only uni-modal datasets, and focus on unitemporal applications. 

To address this gap, we propose PANGAEA, a comprehensive and globally inclusive benchmark for GFMs. PANGAEA is designed to evaluate models across a diverse set of tasks. It spans multiple domains, while incorporating datasets with diverse temporal configurations, spatial resolutions, and sensor modalities. 

A representative set of models was selected for evaluation on our benchmark, guided by criteria emphasizing methodological diversity, impact, and reproducibility. This included approaches such as multi-modal contrastive learning, masked image modeling, and supervised training. Our analysis highlights key factors influencing GFM performance, including the characteristics of pre-training datasets, such as sensor spectral and spatial resolutions. Models trained on datasets with richer spectral and spatial detail excel in tasks requiring those features. However, GFMs do not consistently outperform task-specific supervised models, particularly when there is a mismatch between pre-training and downstream data characteristics (e.g., RGB vs. multispectral). Similar trends are observed across applications such as time-series analysis, crop monitoring, and canopy height prediction. 

To promote transparency and collaboration, we provide a fully open-source evaluation framework, enabling reproducibility and fostering trust in GFM evaluations. This benchmark is designed to be modular and extensible, accommodating new datasets, tasks, and models as the field evolves. Our contributions include a robust and easy-to-use codebase for standardized benchmarking, a diverse evaluation protocol covering a wide range of datasets and sensor types, and insights into GFM performance gaps. "	

[Back to top of page](#top)

<a name="aleksis"></a>
**18. Aleksis Pirinen and Olof Mogren**<br />
**Title**: TBA<br />
**Abstract**: TBA

[Back to top of page](#top)

<a name="puliti"></a>
**19. Stefano Puliti**<br />
**Title**: Leveraging NFI image data for large-scale forest biodiversity monitoring<br />
**Abstract**: National Forest Inventory (NFI) images provide a unique opportunity for systematic and unbiased biodiversity assessments across large spatial scales. Building on our previous work, we expand the use of NFI image data by integrating smartphone-captured forest scenes to enhance forest scene understanding and the estimation of key biodiversity variables, such as species richness and abundance. Unlike citizen science data, NFI images follow a structured sampling design, ensuring comprehensive national coverage and robust biodiversity estimates. As part of the Small4Good EU project, we utilize NFI datasets spanning European biomes, including extensive image collections from the Norwegian, Swiss, and Spanish NFIs—comprising approximately 70K plots and 280K images. A subset of these images is currently being annotated to train supervised forest vision models. By leveraging existing (e.g. iNaturalist) and new deep learning models and image-based biodiversity large-scale estimation, this research aims to advance automated biodiversity monitoring, providing scalable and reproducible methods for ecosystem assessment and conservation planning.


[Back to top of page](#top)

<a name="laura"></a>
**20. Laura Helene Rasmussen**<br />
**Title**: Quantifying the variability of winter climate in the Arctic<br />
**Abstract**: Studies show that a trend towards warmer ecosystems in the Arctic in the 90s and early 2000s has disappeared, however, this does not mean that climate has stabilized. Variability in climate has increased rapidly, and long-term monitoring programs show that winters, spring seasons and summers have become so much more variable that the ecosystems, which are used to more stable, reliable conditions, have an even harder time to adapt compared to a stable trend of e.g. earlier snowmelt.

In this project, we take the focus off of the trend and instead focus on developing a quantitative measure of variability in winter climate. We asked arctic ecosystem scientists, arctic local governmental offices and Arctic indigenous groups to help us identify the most important winter phenomena, whose variability matters to them, and which would be useful to include in a Winter Variability Index (WVI).

We then extracted these phenomena from a pan-Arctic in situ measured data set, reduced dimensions and extracted features in order to identify patterns in variability such as e.g. geographic patterns or climatological patterns. Next step is to classify the Arctic into groups based on their WVI and use the extracted patterns to develop a tool that local authorities, scientists or Arctic peoples can use to compare their own data or area to the rest of the Arctic."	

[Back to top of page](#top)

<a name="heather"></a>
**22. Heather Reese**<br />
**Title**: Subarctic tundra change mapping with Earth Observation and machine learning<br />
**Abstract**: Climate changes in subarctic Sweden include warmer temperatures, change in snow cover and precipitation, and change in season length. This exerts pressure on tundra vegetation, leading over time to increased vegetation biomass (e.g., shrubification) as well as decreased biomass (e.g., due to frost drought). Earth observation (EO) data from satellites in combination with other geographic data facilitate the identification of vegetation change as well as potential drivers of these changes. Using a Random Forest algorithm together with Landsat and Sentinel-2 EO data,  climate-induced changes around the Latnjajaure research station, near Abisko, Sweden, are mapped and important parameters for change are identified. 	

[Back to top of page](#top)

<a name="jaime"></a>
**22. Jaime Caballer Revenga**<br />
**Title**: Self-supervised segmentation of environmental spectroscopic imagery benefits from phenology trajectories<br />
**Abstract**: This study explores two related approaches for vegetation type classification and clustering of vegetation cover types using the hyperspectral images (HSI) collected by the program AVIRIS-NG (JPL-NASA), 
using self-supervised learning (SSL) methods, particularly focusing on the spectral trajectory of pixels over time - caused by phenological changes. The study site is Dangermond Preserve (Santa Barbara, California, USA), where three main vegetation types cover this (Mediterranean-climatic) region: (i) shrubland, (ii) grassland and (iii) deciduous oak forests.

We first investigate the use of 3 SSL methods (Barlow Twins, MoCo-V2 and SwAV) for pixel-wise vegetation type classification. . The three methods use Resnet50 as backbone, and have been trained for classification of RGB histology data. The task aims to (i) transfer the pretrained models to segmentation and (ii) test the robustness of SSL methods against the impact of senescence of vegetation on the spectral reflectance signal across different vegetation types. The study utilizes geographically rectified surface reflectance L2A data from the Dangermond Preserve, with a time span covering 13 consecutive dates corresponding to aerial surveys throughout the growing season (February to September 2022). The objective of this experiment is to understand how model performance evolves over time and whether including specific temporal points, such as the transition between phenophases, improves segmentation accuracy for particular vegetation types.

Then, we explore clustering of "spectrally-similar" pixels to identify whether these clusters correspond to functional vegetation groups, as inspired by the concept of "spectral species." Instead of using traditional PCA, which sacrifices dimensionality, this study employs SSL to train the models on unlabeled data with specific augmentations to cluster pixels according to defined spectral criteria. Afterward, via linear probing and shallow classifiers, are used to evaluate the clustering results. This experiment aims to assess the ability of the model to identify spectral clusters in vegetation data and their functional relevance.

Furthermore, a sub-experiment analyzes the clustering potential of both the reflectance signature and the ""reflectance trajectory"" of pixels across multiple dates. The findings reveal how spectral trajectories, particularly those showing seasonal transitions, may enhance clustering and segmentation performance.

By integrating temporal data and spectral features, this study aims to advance methods for vegetation cover classification and spectral clustering, offering new insights into the role of spectral trajectories and
phenological changes in remote sensing analysis.

[Back to top of page](#top)

<a name="alan"></a>
**23. Alan Said**<br />
**Title**: Accountability and sustainability in AI: reducing the environmental footprint of ai research<br />
**Abstract**: Artificial intelligence continues to drive transformative advances across diverse sectors, from healthcare and transportation to digital services. However, the rapid growth and complexity of AI technologies result in considerable environmental impacts, driven by increased computational demands and associated carbon emissions. Recent studies highlight that typical AI experiments, particularly involving deep-learning models, have significant carbon footprints, underscoring the critical need for sustainability in AI development.

Broad strategies to measure, understand, and reduce AI’s ecological impact include optimizing model efficiency, adopting streamlined and resource-conscious algorithms, and implementing comprehensive energy profiling. Open-source tools and frameworks supporting these methods enable transparent reporting and reproducible research. Embedding accountability, transparency, and sustainability into the foundation of AI research aligns technological innovation with global environmental goals, promoting responsible and sustainable advancements in AI.


[Back to top of page](#top)

<a name="hui"></a>
**24. Hui Zhang**<br />
**Title**: Towards vertical vegetation structure models<br />
**Abstract**: 
Vertical vegetation structure provides critical insights into understory dynamics that cannot be captured by
canopy top height alone. This structural information has the potential to reveal nuanced ecosystem response
to gradual climate shifts and disturbances such as wildfires, deforestation, and forest degradation. However,
existing global-scale studies mainly focus on canopy top height or single descriptors of vertical structure
at low spatial resolution. Here, we address this gap by integrating full-waveform lidar observations from
the Global Ecosystem Dynamics Investigation (GEDI) into wall-to-wall forest monitoring using Sentinel-2
optical images. Existing canopy top height maps use different relative height metrics as a proxy for canopy
top height, which makes them hard to compare. By estimating the full vertical profile from Sentinel-2 input
images, we can now compare our resulting 3D map with all existing canopy top height definitions. Our
results show that our vertical vegetation structure model performs favorably against the state-of-the-art
canopy top height maps, while providing structure data beyond the top height. We see great potential in
these fully vertical structure maps for advancing habitat stratification and biodiversity conservation and for
reducing the uncertainty in aboveground carbon stock estimation.



[Back to top of page](#top)

<a name="anupama"></a>
**27. Anupama Xavier**<br />
**Title**: Comparative predictability of eastern and western north pacific blocking events<br />
**Abstract**: North Pacific blocking patterns, defined by persistent high-pressure systems that disrupt atmospheric circulation, are pivotal elements of mid-latitude weather dynamics. These blocking events play a significant role in shaping regional weather extremes, such as prolonged cold spells or heatwaves, and can redirect storm tracks across the Pacific. For instance, the 2021 Pacific Northwest heatwave demonstrated the profound impact of blocking on terrestrial temperatures, where an upstream cyclone acted as a diabatic source of wave activity, intensifying the blocking system. This led to heat-trapping stable stratification, which elevated surface temperatures to unprecedented levels (Neal et al., 2022). Similarly, marine heatwaves in the Northeast Pacific have been linked to high-latitude blocking events, which weaken westerly winds, suppress southward Ekman transport, and enhance ocean stratification, thereby increasing sea surface temperatures (Niu et al., 2023). The predictability of North Pacific blocking events is governed by the intricate interplay of large-scale atmospheric dynamics, ocean-atmosphere interactions, and internal variability (Smith et al., 2020). This study investigates the differences in predictability between eastern and western North Pacific blocking events, using a modified version of the Davini et al. (2012) blocking index to distinguish their geographical locations. Identified blocking events were tracked using a block-tracking algorithm until they dissipated. Predictability was assessed by identifying an analogue pair for each blocking event. Specifically, after classifying blocks as eastern or western, geopotential height maps for each event were compared to all other days in the dataset. The analogue pair for an event was defined as the day with the smallest root mean square (RMS) distance. Predictability was then evaluated by averaging the error evolution of the tracks between events in each analogue pair. Using CMIP6 model simulations, the study revealed that eastern blocks are significantly more persistent and stable than their western counterparts. Eastern blocks exhibited longer durations and greater resistance to atmospheric variability, resulting in improved forecast accuracy. In contrast, western blocks were found to be more transient and challenging to predict due to their susceptibility to dynamic instabilities.	

[Back to top of page](#top)

